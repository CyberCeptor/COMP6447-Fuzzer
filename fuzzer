#!/usr/bin/env python3
from io import FileIO
import subprocess
import sys
from time import sleep
import breakpoint_finder
import format_finder
import threading
import _thread as thread
import random
from tempfile import TemporaryFile
from scipy.optimize import minimize, Bounds
from combiner import apply, get_dim
import breakpoint_finder
import multiprocessing
from mutator_plaintext import *
from mutator_json import *

program = sys.argv[1]
input = sys.argv[2]

with open(input, "rb") as f:
    sample_text = f.read()

lock = threading.Lock()
def write_out_bad(text: bytes):
    """
    Write out the failing text. Also acquire a lock and kill the fuzzer to stop
    it immediately and to prevent multiple writers.
    """
    lock.acquire() # never release so that nothing else can possibly write out.
    print('v bad')
    with open("bad.txt", "wb") as f:
        f.write(text)
    thread.interrupt_main()

def get_mutators(text):
    # Always have the plaintext ones.
    mutators = [SubstringMutator(), BitFlipMutator(), ByteFlipMutator(),
        RepeatMutator()]
    if format_finder.try_csv(text):
        mutators.append(CSVRepeatRowMutator())
        mutators.append(CSVEmptyRowMutator())
        mutators.append(CSVRepeatColMutator())
        mutators.append(CSVEmptyColMutator())
        mutators.append(CSVEmptyColHeaderMutator())
        mutators.append(CSVCellMultiplierMutator())
        mutators.append(CSVEmptyCellMutator())
    if format_finder.try_json(text):
        mutators.extend([JsonIntMutator(), JsonFloatMutator()] * 3)
    if format_finder.try_xml(text):
        #mutators.append(XMLMutator())
        pass
    if format_finder.try_jpg(text):
        #mutators.append(JPGMutator())
        pass
    if format_finder.try_elf(text):
        #mutators.append(ELFMutator())
        pass
    return mutators

command_str = breakpoint_finder.gdb_command_str(program)
mutators = get_mutators(sample_text)

CRASH_VALUE = -100000000

def get_until_gdb(io: FileIO) -> bytes:
    """
    Read from the io until the gdb command signature is reached.
    Returns the full string up to that point then resets the buffer.
    """
    io.seek(0)
    txt = io.readall()
    while b"(gdb) " not in txt:
        sleep(0.5)
        io.seek(0)
        txt = io.readall()
        #print(txt)
    io.truncate(0)
    io.seek(0)
    return txt

def count_coverage(gdb_instance: subprocess.Popen, input: bytes, out_pipe: "FileIO") -> int:
    # Run and count breakpoints hit for the given input.
    # No resetting needed because the run command does that for us.

    curr_thread = threading.get_ident()

    with open(f'/tmp/input{curr_thread}', 'wb') as f:
        f.write(input)

    count = -random.random()
    # Timer is longer than it feels it should be. But gdb slows down a lot.
    timer = threading.Timer(5.0, gdb_instance.kill)
    try:
        timer.start()
        gdb_instance.stdin.write(f'run < /tmp/input{curr_thread} > /dev/null\n'.encode())
        gdb_instance.stdin.flush()
        # Wait for program to finish.
        get_until_gdb(out_pipe)

        gdb_instance.stdin.write('info breakpoints\n'.encode())
        gdb_instance.stdin.flush()
        
        # breakpoint info table.
        breakpoint_info = get_until_gdb(out_pipe)
        #print('breakpoint info:', breakpoint_info)

        # get the exit code
        gdb_instance.stdin.write('print $_exitcode\n'.encode())
        gdb_instance.stdin.flush()
        exit_code = get_until_gdb(out_pipe)
        exit_code = exit_code.split(b" ")[2].split(b"\n")[0]
        #print('exit code:', exit_code)

        if exit_code != b"0":
            # Found a crash so write it out and kill the fuzzer.
            write_out_bad(input)

        count = -breakpoint_finder.count_total_hits(breakpoint_info) / 10
        #print("breakpoint score:", count)
        #thread.interrupt_main()
    finally:
        timer.cancel()

    return count

def thread_run():
    # make gdb instance. Apply breakpoints

    out_pipe = TemporaryFile(buffering=0)

    gdb_instance = subprocess.Popen(['gdb', '-q', '--nx', program],
        stdin=subprocess.PIPE, stdout=out_pipe)

    gdb_instance.stdin.write(b"set logging on\n")

    gdb_instance.stdin.write(command_str.encode())
    gdb_instance.stdin.flush()
    sleep(0.5)

    # Make sure the buffer is clear before going again.
    out_pipe.seek(0)
    out_pipe.readall()
    #print("start: ", out_pipe.readall())
    out_pipe.truncate(0)
    out_pipe.seek(0)

    # get a random sequence of mutators to apply.
    num_choices = random.randrange(1, len(mutators) // 2)
    methods = random.choices(mutators, k=num_choices)
    if get_dim(methods) < 1:
        return

    def objective(vec):
        return count_coverage(gdb_instance, apply(sample_text, methods, vec), out_pipe)
    def timer_expire():
        raise TimeoutError()
    timer = threading.Timer(30.0, timer_expire)
    # Begin minimisation from a random starting vector.
    bounds = Bounds(0, 1)
    try:
        timer.start()
        minimize(objective, np.random.rand(get_dim(methods)), bounds=bounds)
    except TimeoutError:
        return

    out_pipe.close()
    gdb_instance.kill()

def thread_run_no_gdb():
    # get a random sequence of mutators to apply.
    num_choices = random.randrange(0, len(mutators) * 2)
    methods = random.choices(mutators, k=num_choices)
    if get_dim(methods) < 1:
        return

    def objective(vec):
        try:
            subprocess.run(program, input=apply(sample_text, methods, vec),
                timeout=0.5, capture_output=True)
        finally:
            return -random.random()
    def timer_expire():
        raise TimeoutError()
    timer = threading.Timer(5.0, timer_expire)
    # Random walk for minimisation. Just try anything really for 5 seconds.
    bounds = Bounds(0, 1)
    try:
        timer.start()
        minimize(objective, np.random.rand(get_dim(methods)), bounds=bounds)
    except TimeoutError:
        return

def fuzz():
    import os
    # Setting a reasonable limit so that the cpu doesn't die.
    cpus = os.cpu_count()
    if cpus is None:
        max_threads = 8
    else:
        max_threads = cpus * 3 + 1
    #max_threads = 2 # for debugging purposes. Lets one thread at a time.

    while True:
        try:
            # Distribute work out and keeping trying until something crashes.
            while threading.active_count() < max_threads:
                t = threading.Thread(target=thread_run, daemon=True)
                t.start()
                t = threading.Thread(target=thread_run_no_gdb, daemon=True)
                t.start()
                sys.stdout.write(".")
                sys.stdout.flush()
            sleep(1.0)
        except KeyboardInterrupt:
            print("Exiting")
            break

def try_empty():
    try:
        p = subprocess.run(program, input=b"", timeout=1.0, capture_output=True)
        if p.returncode != 0:
            write_out_bad(b"")
    except subprocess.TimeoutExpired:
        # timed out.
        pass

def try_repeat():
    while True:
        repeat = random.randrange(0, 100000)
        input = sample_text * repeat
        try:
            p = subprocess.run(program, input=input, timeout=1.0, capture_output=True)
            if p.returncode != 0:
                write_out_bad(input)
        except subprocess.TimeoutExpired:
            # timed out.
            pass

def try_simple():
    # Start threads for the simple cases
    threading.Thread(target=try_empty, daemon=True).start()
    threading.Thread(target=try_repeat, daemon=True).start()

def main():
    try:
        try_simple()
        fuzz()
    except Exception as e:
        print(e.args)
        # Marker that we finished.
        # program exit will kill all the threads

if __name__ == "__main__":
    #thread_run()
    main()
